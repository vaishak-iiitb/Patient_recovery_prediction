{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c2a55-69fa-4d51-8575-9a6751eceb42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:13:59.940922Z",
     "iopub.status.busy": "2025-10-26T04:13:59.940572Z",
     "iopub.status.idle": "2025-10-26T04:13:59.951321Z",
     "shell.execute_reply": "2025-10-26T04:13:59.950305Z",
     "shell.execute_reply.started": "2025-10-26T04:13:59.940888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820bdc06",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f29b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:13:59.953311Z",
     "iopub.status.busy": "2025-10-26T04:13:59.952868Z",
     "iopub.status.idle": "2025-10-26T04:13:59.977585Z",
     "shell.execute_reply": "2025-10-26T04:13:59.976407Z",
     "shell.execute_reply.started": "2025-10-26T04:13:59.953270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\" All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2e6f3",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae2f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:13:59.978806Z",
     "iopub.status.busy": "2025-10-26T04:13:59.978546Z",
     "iopub.status.idle": "2025-10-26T04:14:00.007340Z",
     "shell.execute_reply": "2025-10-26T04:14:00.006276Z",
     "shell.execute_reply.started": "2025-10-26T04:13:59.978777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load training and test datasets\n",
    "train_df = pd.read_csv('/kaggle/input/Patient-Recovery-Prediction-Challenge/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/Patient-Recovery-Prediction-Challenge/test.csv')\n",
    "\n",
    "print(\" Dataset loaded successfully!\")\n",
    "print(f\"\\nTraining set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f605f3",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 3.1 Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcae901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.010329Z",
     "iopub.status.busy": "2025-10-26T04:14:00.010064Z",
     "iopub.status.idle": "2025-10-26T04:14:00.022111Z",
     "shell.execute_reply": "2025-10-26T04:14:00.021141Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.010310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"=\" * 80)\n",
    "print(\"FIRST 10 ROWS OF TRAINING DATA\")\n",
    "print(\"=\" * 80)\n",
    "display(train_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9fb45a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.023414Z",
     "iopub.status.busy": "2025-10-26T04:14:00.023076Z",
     "iopub.status.idle": "2025-10-26T04:14:00.049950Z",
     "shell.execute_reply": "2025-10-26T04:14:00.048944Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.023393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data info\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "train_df.info()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COLUMN NAMES\")\n",
    "print(\"=\" * 80)\n",
    "print(train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c26724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.051332Z",
     "iopub.status.busy": "2025-10-26T04:14:00.051057Z",
     "iopub.status.idle": "2025-10-26T04:14:00.089703Z",
     "shell.execute_reply": "2025-10-26T04:14:00.088669Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.051312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "display(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db361926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.091399Z",
     "iopub.status.busy": "2025-10-26T04:14:00.091065Z",
     "iopub.status.idle": "2025-10-26T04:14:00.100769Z",
     "shell.execute_reply": "2025-10-26T04:14:00.099551Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.091378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\" * 80)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\" * 80)\n",
    "missing_values = train_df.isnull().sum()\n",
    "print(missing_values)\n",
    "print(f\"\\n Total missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b350ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.102299Z",
     "iopub.status.busy": "2025-10-26T04:14:00.101797Z",
     "iopub.status.idle": "2025-10-26T04:14:00.125145Z",
     "shell.execute_reply": "2025-10-26T04:14:00.123928Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.102272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"=\" * 80)\n",
    "print(\"DUPLICATE CHECK\")\n",
    "print(\"=\" * 80)\n",
    "duplicates = train_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e8982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.128334Z",
     "iopub.status.busy": "2025-10-26T04:14:00.127502Z",
     "iopub.status.idle": "2025-10-26T04:14:00.149887Z",
     "shell.execute_reply": "2025-10-26T04:14:00.148587Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.128304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Analyze categorical variable\n",
    "print(\"=\" * 80)\n",
    "print(\"LIFESTYLE ACTIVITIES DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "lifestyle_counts = train_df['Lifestyle Activities'].value_counts()\n",
    "print(lifestyle_counts)\n",
    "print(f\"\\nPercentage distribution:\")\n",
    "print(train_df['Lifestyle Activities'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d18ed",
   "metadata": {},
   "source": [
    "### 3.2 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf1e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.151336Z",
     "iopub.status.busy": "2025-10-26T04:14:00.151016Z",
     "iopub.status.idle": "2025-10-26T04:14:00.180921Z",
     "shell.execute_reply": "2025-10-26T04:14:00.179546Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.151316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Target variable statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"TARGET VARIABLE: RECOVERY INDEX\")\n",
    "print(\"=\" * 80)\n",
    "print(train_df['Recovery Index'].describe())\n",
    "print(f\"\\nSkewness: {train_df['Recovery Index'].skew():.4f}\")\n",
    "print(f\"Kurtosis: {train_df['Recovery Index'].kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4646c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.183564Z",
     "iopub.status.busy": "2025-10-26T04:14:00.183300Z",
     "iopub.status.idle": "2025-10-26T04:14:00.738798Z",
     "shell.execute_reply": "2025-10-26T04:14:00.737763Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.183544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(train_df['Recovery Index'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Recovery Index', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Recovery Index', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(train_df['Recovery Index'].mean(), color='red', linestyle='--', \n",
    "                linewidth=2, label=f'Mean: {train_df[\"Recovery Index\"].mean():.2f}')\n",
    "axes[0].axvline(train_df['Recovery Index'].median(), color='green', linestyle='--', \n",
    "                linewidth=2, label=f'Median: {train_df[\"Recovery Index\"].median():.2f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(train_df['Recovery Index'], vert=True, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "                medianprops=dict(color='red', linewidth=2),\n",
    "                whiskerprops=dict(color='blue'),\n",
    "                capprops=dict(color='blue'))\n",
    "axes[1].set_ylabel('Recovery Index', fontsize=12)\n",
    "axes[1].set_title('Box Plot of Recovery Index', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ec127",
   "metadata": {},
   "source": [
    "### 3.3 Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6ab1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:00.740388Z",
     "iopub.status.busy": "2025-10-26T04:14:00.739890Z",
     "iopub.status.idle": "2025-10-26T04:14:02.026195Z",
     "shell.execute_reply": "2025-10-26T04:14:02.024577Z",
     "shell.execute_reply.started": "2025-10-26T04:14:00.740357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Distribution of all numerical features\n",
    "numerical_features = ['Therapy Hours', 'Initial Health Score', 'Average Sleep Hours', \n",
    "                      'Follow-Up Sessions', 'Recovery Index']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_features):\n",
    "    axes[idx].hist(train_df[col], bins=20, color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_xlabel(col, fontsize=11)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].axvline(train_df[col].mean(), color='red', linestyle='--', \n",
    "                     linewidth=2, label=f'Mean: {train_df[col].mean():.2f}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb0f8d",
   "metadata": {},
   "source": [
    "### 3.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f489e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:02.027745Z",
     "iopub.status.busy": "2025-10-26T04:14:02.027241Z",
     "iopub.status.idle": "2025-10-26T04:14:02.415932Z",
     "shell.execute_reply": "2025-10-26T04:14:02.414937Z",
     "shell.execute_reply.started": "2025-10-26T04:14:02.027719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a copy and encode categorical variable for correlation\n",
    "train_encoded = train_df.copy()\n",
    "train_encoded['Lifestyle Activities'] = (train_encoded['Lifestyle Activities'] == 'Yes').astype(int)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = train_encoded.drop('Id', axis=1).corr()\n",
    "\n",
    "# Display correlation with target\n",
    "print(\"=\" * 80)\n",
    "print(\"CORRELATION WITH RECOVERY INDEX\")\n",
    "print(\"=\" * 80)\n",
    "target_corr = correlation_matrix['Recovery Index'].sort_values(ascending=False)\n",
    "print(target_corr)\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.3f', square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6515ebb-0de0-48e6-a178-288b911a1a37",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53841c60",
   "metadata": {},
   "source": [
    "### 3.5 Bivariate Analysis - Features vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c70b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:02.417539Z",
     "iopub.status.busy": "2025-10-26T04:14:02.417219Z",
     "iopub.status.idle": "2025-10-26T04:14:04.270562Z",
     "shell.execute_reply": "2025-10-26T04:14:04.269523Z",
     "shell.execute_reply.started": "2025-10-26T04:14:02.417516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Scatter plots: Each feature vs Recovery Index\n",
    "features = ['Therapy Hours', 'Initial Health Score', 'Average Sleep Hours', 'Follow-Up Sessions']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    axes[idx].scatter(train_df[feature], train_df['Recovery Index'], \n",
    "                     alpha=0.5, s=20, color='steelblue', edgecolors='black', linewidth=0.3)\n",
    "    axes[idx].set_xlabel(feature, fontsize=11)\n",
    "    axes[idx].set_ylabel('Recovery Index', fontsize=11)\n",
    "    axes[idx].set_title(f'{feature} vs Recovery Index', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(train_df[feature], train_df['Recovery Index'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[idx].plot(train_df[feature], p(train_df[feature]), \n",
    "                  \"r--\", linewidth=2, label='Trend line')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4058a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:04.271827Z",
     "iopub.status.busy": "2025-10-26T04:14:04.271472Z",
     "iopub.status.idle": "2025-10-26T04:14:04.566790Z",
     "shell.execute_reply": "2025-10-26T04:14:04.565915Z",
     "shell.execute_reply.started": "2025-10-26T04:14:04.271801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Box plot: Lifestyle Activities vs Recovery Index\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_df.boxplot(column='Recovery Index', by='Lifestyle Activities', \n",
    "                 patch_artist=True, figsize=(10, 6))\n",
    "plt.suptitle('')\n",
    "plt.title('Recovery Index by Lifestyle Activities', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Lifestyle Activities', fontsize=12)\n",
    "plt.ylabel('Recovery Index', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics by Lifestyle Activities\n",
    "print(\"=\" * 80)\n",
    "print(\"RECOVERY INDEX STATISTICS BY LIFESTYLE ACTIVITIES\")\n",
    "print(\"=\" * 80)\n",
    "print(train_df.groupby('Lifestyle Activities')['Recovery Index'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e70aa",
   "metadata": {},
   "source": [
    "### 3.6 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc90ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:04.570658Z",
     "iopub.status.busy": "2025-10-26T04:14:04.570258Z",
     "iopub.status.idle": "2025-10-26T04:14:05.495166Z",
     "shell.execute_reply": "2025-10-26T04:14:05.494143Z",
     "shell.execute_reply.started": "2025-10-26T04:14:04.570630Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "features_to_check = ['Therapy Hours', 'Initial Health Score', 'Average Sleep Hours', \n",
    "                     'Follow-Up Sessions', 'Recovery Index']\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(18, 5))\n",
    "\n",
    "for idx, feature in enumerate(features_to_check):\n",
    "    axes[idx].boxplot(train_df[feature], vert=True, patch_artist=True,\n",
    "                     boxprops=dict(facecolor='lightgreen', color='darkgreen'),\n",
    "                     medianprops=dict(color='red', linewidth=2))\n",
    "    axes[idx].set_ylabel(feature, fontsize=10)\n",
    "    axes[idx].set_title(f'{feature}', fontsize=11, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Outlier Detection via Box Plots', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate outliers using IQR method\n",
    "print(\"=\" * 80)\n",
    "print(\"OUTLIER ANALYSIS (IQR METHOD)\")\n",
    "print(\"=\" * 80)\n",
    "for feature in features_to_check:\n",
    "    Q1 = train_df[feature].quantile(0.25)\n",
    "    Q3 = train_df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = train_df[(train_df[feature] < lower_bound) | (train_df[feature] > upper_bound)]\n",
    "    print(f\"{feature}: {len(outliers)} outliers ({len(outliers)/len(train_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c24b6f",
   "metadata": {},
   "source": [
    "### 3.7 Pair Plot (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb51b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:05.496782Z",
     "iopub.status.busy": "2025-10-26T04:14:05.496446Z",
     "iopub.status.idle": "2025-10-26T04:14:12.048622Z",
     "shell.execute_reply": "2025-10-26T04:14:12.046948Z",
     "shell.execute_reply.started": "2025-10-26T04:14:05.496751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pair plot (using a sample for faster rendering)\n",
    "sample_df = train_df.sample(n=min(1000, len(train_df)), random_state=42)\n",
    "sns.pairplot(sample_df[['Therapy Hours', 'Initial Health Score', 'Average Sleep Hours', \n",
    "                         'Follow-Up Sessions', 'Recovery Index']], \n",
    "             diag_kind='kde', plot_kws={'alpha': 0.6, 's': 30}, height=2.5)\n",
    "plt.suptitle('Pair Plot of Features (Sample)', y=1.01, fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19108323",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd140048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.050146Z",
     "iopub.status.busy": "2025-10-26T04:14:12.049797Z",
     "iopub.status.idle": "2025-10-26T04:14:12.065681Z",
     "shell.execute_reply": "2025-10-26T04:14:12.064342Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.050119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_df.drop(['Id', 'Recovery Index'], axis=1)\n",
    "y = train_df['Recovery Index']\n",
    "\n",
    "# Encode categorical variable (Lifestyle Activities)\n",
    "label_encoder = LabelEncoder()\n",
    "X['Lifestyle Activities'] = label_encoder.fit_transform(X['Lifestyle Activities'])\n",
    "\n",
    "print(\" Lifestyle Activities encoded (No=0, Yes=1)\")\n",
    "print(f\"\\nFeature columns: {X.columns.tolist()}\")\n",
    "print(f\"Target variable: Recovery Index\")\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134921bf-3e58-495c-a61d-d6d47a22e358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.067477Z",
     "iopub.status.busy": "2025-10-26T04:14:12.067097Z",
     "iopub.status.idle": "2025-10-26T04:14:12.134944Z",
     "shell.execute_reply": "2025-10-26T04:14:12.133737Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.067444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    \"\"\"\n",
    "    Create advanced features from existing ones.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe with features\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_enhanced : pandas.DataFrame\n",
    "        DataFrame with additional engineered features\n",
    "    \"\"\"\n",
    "    df_enhanced = df.copy()\n",
    "    \n",
    "    # Interaction Features\n",
    "    df_enhanced['therapy_health_interaction'] = df_enhanced['Therapy Hours'] * df_enhanced['Initial Health Score']\n",
    "    df_enhanced['therapy_followup_interaction'] = df_enhanced['Therapy Hours'] * df_enhanced['Follow-Up Sessions']\n",
    "    df_enhanced['sleep_health_interaction'] = df_enhanced['Average Sleep Hours'] * df_enhanced['Initial Health Score']\n",
    "    df_enhanced['therapy_sleep_interaction'] = df_enhanced['Therapy Hours'] * df_enhanced['Average Sleep Hours']\n",
    "    \n",
    "    # Ratio Features\n",
    "    df_enhanced['therapy_per_followup'] = df_enhanced['Therapy Hours'] / (df_enhanced['Follow-Up Sessions'] + 1)  # +1 to avoid division by zero\n",
    "    df_enhanced['health_per_sleep'] = df_enhanced['Initial Health Score'] / (df_enhanced['Average Sleep Hours'] + 1)\n",
    "    df_enhanced['therapy_per_sleep'] = df_enhanced['Therapy Hours'] / (df_enhanced['Average Sleep Hours'] + 1)\n",
    "    df_enhanced['followup_per_therapy'] = df_enhanced['Follow-Up Sessions'] / (df_enhanced['Therapy Hours'] + 1)\n",
    "    \n",
    "    # Polynomial Features (degree 2 for most important features)\n",
    "    df_enhanced['therapy_hours_squared'] = df_enhanced['Therapy Hours'] ** 2\n",
    "    df_enhanced['health_score_squared'] = df_enhanced['Initial Health Score'] ** 2\n",
    "    df_enhanced['sleep_hours_squared'] = df_enhanced['Average Sleep Hours'] ** 2\n",
    "    df_enhanced['followup_squared'] = df_enhanced['Follow-Up Sessions'] ** 2\n",
    "    \n",
    "    # Binning Features (create categorical versions)\n",
    "    df_enhanced['sleep_category'] = pd.cut(df_enhanced['Average Sleep Hours'], \n",
    "                                            bins=[0, 5, 7, 9, 12], \n",
    "                                            labels=[0, 1, 2, 3], right=False)\n",
    "    df_enhanced['health_category'] = pd.cut(df_enhanced['Initial Health Score'], \n",
    "                                             bins=[0, 25, 50, 75, 100], \n",
    "                                             labels=[0, 1, 2, 3], right=False)\n",
    "    df_enhanced['therapy_level'] = pd.cut(df_enhanced['Therapy Hours'], \n",
    "                                           bins=[0, 3, 6, 9, 100], \n",
    "                                           labels=[0, 1, 2, 3], right=False)\n",
    "    \n",
    "    # Convert categorical bins to numeric\n",
    "    df_enhanced['sleep_category'] = df_enhanced['sleep_category'].astype(float)\n",
    "    df_enhanced['health_category'] = df_enhanced['health_category'].astype(float)\n",
    "    df_enhanced['therapy_level'] = df_enhanced['therapy_level'].astype(float)\n",
    "    \n",
    "    # Combined score features\n",
    "    df_enhanced['overall_care_score'] = (df_enhanced['Therapy Hours'] + \n",
    "                                          df_enhanced['Follow-Up Sessions'] + \n",
    "                                          df_enhanced['Initial Health Score'] +\n",
    "                                          df_enhanced['Average Sleep Hours']) / 4\n",
    "    \n",
    "    df_enhanced['weighted_care_score'] = (df_enhanced['Therapy Hours'] * 0.3 + \n",
    "                                           df_enhanced['Follow-Up Sessions'] * 0.2 + \n",
    "                                           df_enhanced['Initial Health Score'] * 0.3 +\n",
    "                                           df_enhanced['Average Sleep Hours'] * 0.2)\n",
    "    \n",
    "    return df_enhanced\n",
    "\n",
    "# Apply feature engineering to training data\n",
    "print(\"=\" * 80)\n",
    "print(\"ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nOriginal features: {X.shape[1]}\")\n",
    "X_engineered = create_advanced_features(X)\n",
    "print(f\"Enhanced features: {X_engineered.shape[1]}\")\n",
    "print(f\"New features added: {X_engineered.shape[1] - X.shape[1]}\")\n",
    "\n",
    "print(f\"\\n New feature list:\")\n",
    "new_features = [col for col in X_engineered.columns if col not in X.columns]\n",
    "for i, feat in enumerate(new_features, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "\n",
    "print(f\"\\n Feature engineering completed!\")\n",
    "print(f\"\\nEnhanced feature set preview:\")\n",
    "display(X_engineered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09522ae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.136266Z",
     "iopub.status.busy": "2025-10-26T04:14:12.135952Z",
     "iopub.status.idle": "2025-10-26T04:14:12.149635Z",
     "shell.execute_reply": "2025-10-26T04:14:12.148555Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.136242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and validation sets (using engineered features)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_engineered, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAIN-VALIDATION SPLIT (With Engineered Features)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({(X_train.shape[0]/X_engineered.shape[0])*100:.1f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples ({(X_val.shape[0]/X_engineered.shape[0])*100:.1f}%)\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "print(f\"\\nTraining target statistics:\")\n",
    "print(f\"  Mean: {y_train.mean():.2f}\")\n",
    "print(f\"  Std: {y_train.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50879c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.151053Z",
     "iopub.status.busy": "2025-10-26T04:14:12.150689Z",
     "iopub.status.idle": "2025-10-26T04:14:12.184696Z",
     "shell.execute_reply": "2025-10-26T04:14:12.183640Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.151001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling (IMPORTANT for Linear Regression with engineered features)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Convert back to DataFrame to preserve column names\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE SCALING (StandardScaler)\")\n",
    "print(\"=\" * 80)\n",
    "print(\" Features scaled to have mean=0 and std=1\")\n",
    "print(f\"\\nScaled training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled validation set shape: {X_val_scaled.shape}\")\n",
    "print(f\"\\nNote: Scaling is crucial for Linear Regression, especially with\")\n",
    "print(f\"      engineered features that have different scales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe728b",
   "metadata": {},
   "source": [
    "## 4.1 Custom Accuracy Metric for Regression\n",
    "\n",
    "Define a tolerance-based accuracy metric: predictions within a threshold are counted as \"correct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a842dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.186146Z",
     "iopub.status.busy": "2025-10-26T04:14:12.185855Z",
     "iopub.status.idle": "2025-10-26T04:14:12.194470Z",
     "shell.execute_reply": "2025-10-26T04:14:12.193610Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.186125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred, tolerance=2.0):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for regression tasks using a tolerance threshold.\n",
    "    Predictions within ±tolerance of actual values are counted as correct.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True values\n",
    "    y_pred : array-like\n",
    "        Predicted values\n",
    "    tolerance : float, default=2.0\n",
    "        Tolerance threshold for considering predictions as \"correct\"\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    accuracy : float\n",
    "        Correct predictions / total predictions\n",
    "    \"\"\"\n",
    "    correct_predictions = np.abs(y_true - y_pred) <= tolerance\n",
    "    accuracy = correct_predictions.sum() / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "# Test the function\n",
    "print(\"=\" * 80)\n",
    "print(\"CUSTOM ACCURACY METRIC FOR REGRESSION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n Function defined: calculate_accuracy(y_true, y_pred, tolerance=2.0)\")\n",
    "print(f\"\\nHow it works:\")\n",
    "print(f\"  - Predictions within ±{2.0} of actual values = 'correct'\")\n",
    "print(f\"  - Accuracy = correct predictions / total predictions\")\n",
    "print(f\"  - Useful for understanding practical prediction accuracy\")\n",
    "print(f\"\\nYou can adjust tolerance based on problem requirements:\")\n",
    "print(f\"  - tolerance=1.0  → stricter (predictions within ±1)\")\n",
    "print(f\"  - tolerance=2.0  → moderate (default)\")\n",
    "print(f\"  - tolerance=5.0  → lenient (predictions within ±5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa533199",
   "metadata": {},
   "source": [
    "## 4.2 Advanced Feature Engineering\n",
    "\n",
    "Create new features to capture complex relationships and improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b81e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.195585Z",
     "iopub.status.busy": "2025-10-26T04:14:12.195349Z",
     "iopub.status.idle": "2025-10-26T04:14:12.261898Z",
     "shell.execute_reply": "2025-10-26T04:14:12.261064Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.195567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    \"\"\"\n",
    "    Create advanced features from existing ones.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe with features\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_enhanced : pandas.DataFrame\n",
    "        DataFrame with additional engineered features\n",
    "    \"\"\"\n",
    "    df_enhanced = df.copy()\n",
    "    \n",
    "    # Interaction Features\n",
    "    df_enhanced['therapy_health_interaction'] = df_enhanced['Therapy Hours'] * df_enhanced['Initial Health Score']\n",
    "    df_enhanced['therapy_followup_interaction'] = df_enhanced['Therapy Hours'] * df_enhanced['Follow-Up Sessions']\n",
    "    df_enhanced['sleep_health_interaction'] = df_enhanced['Average Sleep Hours'] * df_enhanced['Initial Health Score']\n",
    "    df_enhanced['therapy_sleep_interaction'] = df_enhanced['Therapy Hours'] * df_enhanced['Average Sleep Hours']\n",
    "    \n",
    "    # Ratio Features\n",
    "    df_enhanced['therapy_per_followup'] = df_enhanced['Therapy Hours'] / (df_enhanced['Follow-Up Sessions'] + 1)  # +1 to avoid division by zero\n",
    "    df_enhanced['health_per_sleep'] = df_enhanced['Initial Health Score'] / (df_enhanced['Average Sleep Hours'] + 1)\n",
    "    df_enhanced['therapy_per_sleep'] = df_enhanced['Therapy Hours'] / (df_enhanced['Average Sleep Hours'] + 1)\n",
    "    df_enhanced['followup_per_therapy'] = df_enhanced['Follow-Up Sessions'] / (df_enhanced['Therapy Hours'] + 1)\n",
    "    \n",
    "    # Polynomial Features (degree 2 for most important features)\n",
    "    df_enhanced['therapy_hours_squared'] = df_enhanced['Therapy Hours'] ** 2\n",
    "    df_enhanced['health_score_squared'] = df_enhanced['Initial Health Score'] ** 2\n",
    "    df_enhanced['sleep_hours_squared'] = df_enhanced['Average Sleep Hours'] ** 2\n",
    "    df_enhanced['followup_squared'] = df_enhanced['Follow-Up Sessions'] ** 2\n",
    "    \n",
    "    # Binning Features (create categorical versions)\n",
    "    df_enhanced['sleep_category'] = pd.cut(df_enhanced['Average Sleep Hours'], \n",
    "                                            bins=[0, 5, 7, 9, 12], \n",
    "                                            labels=[0, 1, 2, 3], right=False)\n",
    "    df_enhanced['health_category'] = pd.cut(df_enhanced['Initial Health Score'], \n",
    "                                             bins=[0, 25, 50, 75, 100], \n",
    "                                             labels=[0, 1, 2, 3], right=False)\n",
    "    df_enhanced['therapy_level'] = pd.cut(df_enhanced['Therapy Hours'], \n",
    "                                           bins=[0, 3, 6, 9, 100], \n",
    "                                           labels=[0, 1, 2, 3], right=False)\n",
    "    \n",
    "    # Convert categorical bins to numeric\n",
    "    df_enhanced['sleep_category'] = df_enhanced['sleep_category'].astype(float)\n",
    "    df_enhanced['health_category'] = df_enhanced['health_category'].astype(float)\n",
    "    df_enhanced['therapy_level'] = df_enhanced['therapy_level'].astype(float)\n",
    "    \n",
    "    # Combined score features\n",
    "    df_enhanced['overall_care_score'] = (df_enhanced['Therapy Hours'] + \n",
    "                                          df_enhanced['Follow-Up Sessions'] + \n",
    "                                          df_enhanced['Initial Health Score'] +\n",
    "                                          df_enhanced['Average Sleep Hours']) / 4\n",
    "    \n",
    "    df_enhanced['weighted_care_score'] = (df_enhanced['Therapy Hours'] * 0.3 + \n",
    "                                           df_enhanced['Follow-Up Sessions'] * 0.2 + \n",
    "                                           df_enhanced['Initial Health Score'] * 0.3 +\n",
    "                                           df_enhanced['Average Sleep Hours'] * 0.2)\n",
    "    \n",
    "    return df_enhanced\n",
    "\n",
    "# Apply feature engineering to training data\n",
    "print(\"=\" * 80)\n",
    "print(\"ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nOriginal features: {X.shape[1]}\")\n",
    "X_engineered = create_advanced_features(X)\n",
    "print(f\"Enhanced features: {X_engineered.shape[1]}\")\n",
    "print(f\"New features added: {X_engineered.shape[1] - X.shape[1]}\")\n",
    "\n",
    "print(f\"\\n New feature list:\")\n",
    "new_features = [col for col in X_engineered.columns if col not in X.columns]\n",
    "for i, feat in enumerate(new_features, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "\n",
    "print(f\"\\n Feature engineering completed!\")\n",
    "print(f\"\\nEnhanced feature set preview:\")\n",
    "display(X_engineered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4cc35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Baseline Model - Linear Regression\n",
    "\n",
    "### 5.1 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707aae6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.263585Z",
     "iopub.status.busy": "2025-10-26T04:14:12.263237Z",
     "iopub.status.idle": "2025-10-26T04:14:12.305188Z",
     "shell.execute_reply": "2025-10-26T04:14:12.304353Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.263556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train Linear Regression model (with engineered features)\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING LINEAR REGRESSION MODEL (With Advanced Features)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "lr_model = Lasso(alpha=0.01)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\" Model trained successfully!\")\n",
    "print(f\"\\nTotal features used: {len(X_engineered.columns)}\")\n",
    "print(f\"  - Original features: {len(X.columns)}\")\n",
    "print(f\"  - Engineered features: {len(X_engineered.columns) - len(X.columns)}\")\n",
    "print(f\"\\nIntercept: {lr_model.intercept_:.4f}\")\n",
    "print(f\"\\nTop 10 coefficients by absolute value:\")\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X_engineered.columns,\n",
    "    'Coefficient': lr_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "for idx, row in coef_df.iterrows():\n",
    "    print(f\"  {row['Feature']:30s}: {row['Coefficient']:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e789468d",
   "metadata": {},
   "source": [
    "### 5.1b Feature Importance Analysis\n",
    "\n",
    "Analyze which features have the strongest impact on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e471b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.308807Z",
     "iopub.status.busy": "2025-10-26T04:14:12.307462Z",
     "iopub.status.idle": "2025-10-26T04:14:12.746326Z",
     "shell.execute_reply": "2025-10-26T04:14:12.745364Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.308776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get feature importance (absolute coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_engineered.columns,\n",
    "    'Coefficient': lr_model.coef_,\n",
    "    'Abs_Coefficient': np.abs(lr_model.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE (Linear Regression Coefficients)\")\n",
    "print(\"=\" * 80)\n",
    "print(feature_importance)\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = min(20, len(feature_importance))  # Show top 20 or all if less\n",
    "top_features = feature_importance.head(top_n)\n",
    "\n",
    "# Create color map: positive coefficients in green, negative in red\n",
    "colors = ['green' if x > 0 else 'red' for x in top_features['Coefficient']]\n",
    "\n",
    "plt.barh(range(len(top_features)), top_features['Coefficient'], color=colors, alpha=0.7, edgecolor='black')\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title(f'Top {top_n} Most Important Features (Linear Regression)\\nGreen = Positive Impact, Red = Negative Impact', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Top 5 Most Important Features (by absolute coefficient):\")\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    direction = \"increases\" if row['Coefficient'] > 0 else \"decreases\"\n",
    "    print(f\"  {row['Feature']}: {row['Coefficient']:+.4f} ({direction} recovery)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7bb0db",
   "metadata": {},
   "source": [
    "### 5.2 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741043ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.747513Z",
     "iopub.status.busy": "2025-10-26T04:14:12.747232Z",
     "iopub.status.idle": "2025-10-26T04:14:12.764428Z",
     "shell.execute_reply": "2025-10-26T04:14:12.763100Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.747492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = lr_model.predict(X_train_scaled)\n",
    "y_val_pred = lr_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "# Calculate ACCURACY (tolerance-based)\n",
    "train_acc = calculate_accuracy(y_train, y_train_pred, tolerance=2.0)\n",
    "val_acc = calculate_accuracy(y_val, y_val_pred, tolerance=2.0)\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL PERFORMANCE METRICS (With Engineered Features)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Metric':<25} {'Training':>15} {'Validation':>15}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'R² Score':<25} {train_r2:>15.4f} {val_r2:>15.4f}\")\n",
    "print(f\"{'RMSE':<25} {train_rmse:>15.4f} {val_rmse:>15.4f}\")\n",
    "print(f\"{'MAE':<25} {train_mae:>15.4f} {val_mae:>15.4f}\")\n",
    "print(f\"{'Accuracy (±2.0)':<25} {train_acc:>15.4f} {val_acc:>15.4f}\")\n",
    "print(f\"{'Accuracy %':<25} {train_acc*100:>14.2f}% {val_acc*100:>14.2f}%\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for overfitting\n",
    "overfitting_diff = abs(train_r2 - val_r2)\n",
    "if overfitting_diff < 0.05:\n",
    "    print(f\"\\n Model is well-balanced (R² difference: {overfitting_diff:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n Potential overfitting detected (R² difference: {overfitting_diff:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b3e9d",
   "metadata": {},
   "source": [
    "### 5.3 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469fae26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.765426Z",
     "iopub.status.busy": "2025-10-26T04:14:12.765146Z",
     "iopub.status.idle": "2025-10-26T04:14:12.902917Z",
     "shell.execute_reply": "2025-10-26T04:14:12.898913Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.765406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "print(\"=\" * 80)\n",
    "print(\"5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, \n",
    "                            cv=kfold, scoring='r2')\n",
    "\n",
    "print(f\"\\nCross-validation R² scores: {cv_scores}\")\n",
    "print(f\"\\nMean CV R² Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "print(f\"Min CV R² Score: {cv_scores.min():.4f}\")\n",
    "print(f\"Max CV R² Score: {cv_scores.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd22c0",
   "metadata": {},
   "source": [
    "### 5.4 Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc20f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:12.905860Z",
     "iopub.status.busy": "2025-10-26T04:14:12.904165Z",
     "iopub.status.idle": "2025-10-26T04:14:13.499479Z",
     "shell.execute_reply": "2025-10-26T04:14:13.497595Z",
     "shell.execute_reply.started": "2025-10-26T04:14:12.905824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot: Actual vs Predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Training set\n",
    "axes[0].scatter(y_train, y_train_pred, alpha=0.5, s=30, color='blue', edgecolors='black', linewidth=0.3)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "            'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Recovery Index', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Recovery Index', fontsize=12)\n",
    "axes[0].set_title(f'Training Set: Actual vs Predicted\\nR² = {train_r2:.4f}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Validation set\n",
    "axes[1].scatter(y_val, y_val_pred, alpha=0.5, s=30, color='green', edgecolors='black', linewidth=0.3)\n",
    "axes[1].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \n",
    "            'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual Recovery Index', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted Recovery Index', fontsize=12)\n",
    "axes[1].set_title(f'Validation Set: Actual vs Predicted\\nR² = {val_r2:.4f}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9f728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:13.501475Z",
     "iopub.status.busy": "2025-10-26T04:14:13.500875Z",
     "iopub.status.idle": "2025-10-26T04:14:14.645200Z",
     "shell.execute_reply": "2025-10-26T04:14:14.644235Z",
     "shell.execute_reply.started": "2025-10-26T04:14:13.501432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Residual Analysis\n",
    "residuals_train = y_train - y_train_pred\n",
    "residuals_val = y_val - y_val_pred\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Training residuals vs predicted\n",
    "axes[0, 0].scatter(y_train_pred, residuals_train, alpha=0.5, s=30, color='blue', edgecolors='black', linewidth=0.3)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Predicted Recovery Index', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Residuals', fontsize=11)\n",
    "axes[0, 0].set_title('Training Set: Residual Plot', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Validation residuals vs predicted\n",
    "axes[0, 1].scatter(y_val_pred, residuals_val, alpha=0.5, s=30, color='green', edgecolors='black', linewidth=0.3)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Predicted Recovery Index', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Residuals', fontsize=11)\n",
    "axes[0, 1].set_title('Validation Set: Residual Plot', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Histogram of training residuals\n",
    "axes[1, 0].hist(residuals_train, bins=30, color='blue', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Residuals', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 0].set_title('Training Set: Residual Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Histogram of validation residuals\n",
    "axes[1, 1].hist(residuals_val, bins=30, color='green', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Residuals', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 1].set_title('Validation Set: Residual Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b4ebd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414f979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:14.646717Z",
     "iopub.status.busy": "2025-10-26T04:14:14.646389Z",
     "iopub.status.idle": "2025-10-26T04:14:14.680257Z",
     "shell.execute_reply": "2025-10-26T04:14:14.678859Z",
     "shell.execute_reply.started": "2025-10-26T04:14:14.646688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare test data with feature engineering\n",
    "X_test = test_df.drop('Id', axis=1).copy()\n",
    "X_test['Lifestyle Activities'] = label_encoder.transform(X_test['Lifestyle Activities'])\n",
    "\n",
    "# Apply feature engineering to test set\n",
    "X_test_engineered = create_advanced_features(X_test)\n",
    "\n",
    "# Scale test features\n",
    "X_test_scaled = scaler.transform(X_test_engineered)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST DATA PREPARATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\" Test data processed with feature engineering\")\n",
    "print(f\"   Original features: {X_test.shape[1]}\")\n",
    "print(f\"   Engineered features: {X_test_engineered.shape[1]}\")\n",
    "print(f\"   Scaled and ready for prediction!\")\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = lr_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"\\n Predictions generated for {len(test_predictions)} test samples\")\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Mean: {test_predictions.mean():.2f}\")\n",
    "print(f\"  Std: {test_predictions.std():.2f}\")\n",
    "print(f\"  Min: {test_predictions.min():.2f}\")\n",
    "print(f\"  Max: {test_predictions.max():.2f}\")\n",
    "print(f\"  Median: {np.median(test_predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7251c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:14.684197Z",
     "iopub.status.busy": "2025-10-26T04:14:14.683875Z",
     "iopub.status.idle": "2025-10-26T04:14:14.722650Z",
     "shell.execute_reply": "2025-10-26T04:14:14.721737Z",
     "shell.execute_reply.started": "2025-10-26T04:14:14.684176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'Recovery Index': test_predictions\n",
    "})\n",
    "\n",
    "# Save to CSV with descriptive filename\n",
    "filename = 'linear_regression_enhanced_with_lasso_submission.csv'\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SUBMISSION FILE CREATED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\" File saved: {filename}\")\n",
    "print(f\"   Model: Linear Regression with Advanced Feature Engineering\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "display(submission.head(10))\n",
    "print(f\"\\nLast 10 predictions:\")\n",
    "display(submission.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc86c9",
   "metadata": {},
   "source": [
    "## 7. Model Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af3faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T04:14:14.724278Z",
     "iopub.status.busy": "2025-10-26T04:14:14.723845Z",
     "iopub.status.idle": "2025-10-26T04:14:14.740015Z",
     "shell.execute_reply": "2025-10-26T04:14:14.738938Z",
     "shell.execute_reply.started": "2025-10-26T04:14:14.724187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE MODEL SUMMARY - ENHANCED LINEAR REGRESSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n ENHANCEMENTS IMPLEMENTED:\")\n",
    "print(\"  1. Advanced Feature Engineering (19+ new features)\")\n",
    "print(\"  2. Interaction Features (therapy × health, sleep × health, etc.)\")\n",
    "print(\"  3. Polynomial Features (squared terms for key features)\")\n",
    "print(\"  4. Ratio Features (therapy per followup, health per sleep, etc.)\")\n",
    "print(\"  5. Binning Features (sleep categories, health categories, therapy levels)\")\n",
    "print(\"  6. Combined Score Features (overall and weighted care scores)\")\n",
    "print(\"  7. Custom Accuracy Metric (tolerance-based for practical insights)\")\n",
    "\n",
    "print(\"\\n DATASET INFORMATION:\")\n",
    "print(f\"  Original features: {X.shape[1]}\")\n",
    "print(f\"  Engineered features: {X_engineered.shape[1]}\")\n",
    "print(f\"  New features added: {X_engineered.shape[1] - X.shape[1]}\")\n",
    "print(f\"  Training samples: {X_train.shape[0]}\")\n",
    "print(f\"  Validation samples: {X_val.shape[0]}\")\n",
    "print(f\"  Test samples: {len(test_predictions)}\")\n",
    "\n",
    "print(\"\\n MODEL PERFORMANCE:\")\n",
    "print(f\"\\n  {'Metric':<25} {'Training':>15} {'Validation':>15}\")\n",
    "print(\"  \" + \"-\" * 70)\n",
    "print(f\"  {'R² Score':<25} {train_r2:>15.4f} {val_r2:>15.4f}\")\n",
    "print(f\"  {'RMSE':<25} {train_rmse:>15.4f} {val_rmse:>15.4f}\")\n",
    "print(f\"  {'MAE':<25} {train_mae:>15.4f} {val_mae:>15.4f}\")\n",
    "print(f\"  {'Accuracy (±2.0)':<25} {train_acc:>15.4f} {val_acc:>15.4f}\")\n",
    "print(f\"  {'Accuracy %':<25} {train_acc*100:>14.2f}% {val_acc*100:>14.2f}%\")\n",
    "\n",
    "print(f\"\\n TOP 5 MOST IMPORTANT FEATURES:\")\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    impact = \"positive\" if row['Coefficient'] > 0 else \"negative\"\n",
    "    print(f\"  {idx+1}. {row['Feature']}: {row['Coefficient']:+.4f} ({impact} impact)\")\n",
    "\n",
    "print(f\"\\n TEST SET PREDICTIONS:\")\n",
    "print(f\"  Number of predictions: {len(test_predictions)}\")\n",
    "print(f\"  Prediction range: [{test_predictions.min():.2f}, {test_predictions.max():.2f}]\")\n",
    "print(f\"  Prediction mean: {test_predictions.mean():.2f}\")\n",
    "print(f\"  Prediction std: {test_predictions.std():.2f}\")\n",
    "\n",
    "print(f\"\\n OUTPUT FILE:\")\n",
    "print(f\"  Submission file: linear_regression_enhanced_submission.csv\")\n",
    "\n",
    "print(f\"\\n KEY INSIGHTS:\")\n",
    "print(f\"  - Linear Regression benefits greatly from feature engineering\")\n",
    "print(f\"  - Feature scaling is crucial for models with different feature scales\")\n",
    "print(f\"  - Interaction and polynomial features capture non-linear relationships\")\n",
    "print(f\"  - Model performance: {val_r2:.4f} R² score on validation set\")\n",
    "print(f\"  - Practical accuracy: {val_acc*100:.2f}% within ±2.0 tolerance\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13903632,
     "sourceId": 116123,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
